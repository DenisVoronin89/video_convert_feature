Внесенные изменения в проект точка сейва 13.12.2024:

1. Сразу прикрутил PostgreSQL
2. Поменял кодек на VP9 (можно рассмотреть еще Н265, но он, как гласит дока - платный, но вроде как можно наколоть систему (см. файл Codecs)
3. Ушел от subprocess в функциях конвертации и извлечения превью (разобрался почему сабпроцесс не есть гуд)
4. Разделил некоторые фукции, пришел к формату(или принципу) SRP
5. Добавил лог на измерение веса файлов
6. Собрана информация по самым распространенным кодекам для обработки видео и сведена в файл Codecs.txt.
   Два подходящих нам выведены в сравнительную таблицу и к ним добавлено более подробное описание
7. Длинну превью вывел в переменную, чтобы проще было потом подогнать по длительности как нам надо
8. Битрейт пока 2М, но руки чешутся 4-5 поставить чтобы качество 4К тянуло (надо это будет протестить на производительность)
9. Добавлены BackgroundTasks для управления задачами, которые будут выполняться в фоне. Использование background_tasks.add_task:
    задачи для конвертации видео, извлечения превью, загрузки в S3 и сохранения в базе данных. После того как задачи добавлены в фон,
    функция возвращает ответ клиенту без задержек, а все ресурсоемкие операции выполняются асинхронно. Тяжелые задачи варятся в фоне,
    клиент не ждет, а юзает нашу приложуху без ожидания и счастлив
    (Надо только потом какое то пуш уведомление прикрутить чтобы клиент видел что фоновые задачи отработали и видос залит)

Внесенные изменения в проект точка сейва 20.12.2024:

1. Код разбит по модулям
2. Доработана таблица, не стал делать промежуточную таблицу (босс сказал проверка оплаты будет по транзакции, смысл кидать все в промежуточную БД?
   Тут либо оплачивают сразу и проверка проходит, так как транзакцию ловим моментом, либо потом снова форму пускай заполняет, так вроде все
   интернет магазины и доски объявлений работают), форма кэшироваться будет на фронте пока проверка платежа идет
3. После кнопки ADD(или PAY может ее назовем?) нас перекидывает на метамаск кошелек - мы платим,
    в это время в фоне уже крутися функция на проверку платежа. Как только поймали платеж
    в фоне начинает крутиться основной процесс конвертация-превью-загрузка-сохранение профиля в БД
4. Реализовано автоматическое удаление временных файлов, запуск в 00:00 ежедневно и сносит все, что старше 48 часов
5. Реализовал фоновые задачи через sub and pub, как просил Евгений (есть куча вопросов спросить Евгения на созвоне)
6. Добавлена таблица с хэштегами, ассоциативная таблица для связи хэштегов и видео, функции для работы с хэштэгаим
7. Переделана логика сохранения в БД, добавлена проверка пользователя по номеру кошелька и соответственно происходит либо
   создание нового юзера либо обновление записей существующего
8. Реализован функционал проверки оплаты и модерации, пока моковый
9. Добавлен функционал сохранения лого (аватарки)
10. Добавлен функционал работы с формами и обработки формы, валидация формы и ее данных
11. Функционал создания папок тоже поменял, сделал переменную с нужным списком директорий (словарь) для простоты расширения функционала
12. Реализовал проверку хэшегов на запрещенные слова, есть узкое место (описано ниже)
13. Реализовано хэширование кошельков (Пожелание босса)
14. Реализовано получение, сохранение и отдача геоданных
15. Все теперь работает через докер, как микросервисы (докерфайлы реализованы кринжово, но работают. Евгений, сильно не бей)))
16. Отлажено и оттестировано, передал Максу в работу


Внесенные изменения в проект точка сейва .2024:

1. Передалана архитектура БД, добавлены избранное, созданные профили вынесены в отдельную таблицу, проложены связи
2. В Редис кэшируем счетчик подписчиков, список избранного для каждого профиля
3. Добавлен функционал для актуализации данных в кэше и БД
4. Написаны эндпоинты для добавления/удаления избранного и уеньшения/увеличения счетчика подписчиков
5. Реализован функционал отдачи первых 50 профилей из кэша(получение 50 профилей по расписанию и кэширование их)
6. Реализованы во всех поисковых эндпоинтах сортировки по популярности и новизне
7. Реализована отдача профилей по городу, по хэштегам
8. Кэширование запросов по хэштегам, по причине что они выполняются чаще и тяжелее
9. Реализована отдача всех профилей
10. Реализована работа с геоданными, постгис
11. Реализован функционал ленивой загрузки
12, Реализован функционал операций, выполняющихся по расписанию, использован АПИшедлер


 УЗКИЕ МЕСТА И ВОЗМОЖНЫЕ ПРОБЛЕМЫ:

1. Бесконечное количество попыток загрузить видео и изображение и будет переполнена папка темп. Пример когда мы после предпросмотра жмем отмену
и грузим новый видос и так бесконечно до сохранения - выглядидт как дэдос (Обсудить с Евгением как лучше запилить и защититься, в безопасность
пока не погружался, исправлю)

2. Второй момент проверка типа файла. Проверка содержимого ресурсоемка и это будет критично когда у нас будет много юзеров,
Да, можно сделать проверку на валидность файлов без их открытия. Это будет базироваться на MIME-типах файлов и расширениях.(сейчас это и сделано)
Однако, это будет не так надежно, как проверка содержимого файлов, поскольку можно столкнуться с ситуациями, когда файл имеет правильный
MIME-тип или расширение, но на самом деле является поврежденным или неправильного формата. Вроде судя по мануалам и бест практикам это
решение самое оптимальное и я выбрал его

3. Проверка на хэштеги с неприменимым контентом: нужно будет сделать более гибкую проверку или добавить список запрещенных слов. Обсудить это с командой и
уточнить требования (ну слов так то вагон, список/кортеж из запрещенных слов делать мы офигеем) - спросить совет у Евгения. Использовать регулярные
выражения для поиска конкретных запрещенных слов или воспользоваться сторонними библиотеками для фильтрации контента.
Оба метода имеют свои преимущества и могут быть использованы в зависимости от нашей задачи. (пока что взял на себя ответственность и
сгенерировал в чате гпт словарь, который содержит в себе все основные плохие запрещенные ключевые слова в ру и енг сегменте)
Юридически это пока узкое место, особенно когда мы начнем уходить от человеческой модерации (еть решение - нейронка, но их дообучать надо)
Сделал пока список запрещенных слов, не нашел адекватной либы которая поддерживает русский запрещенный завуалированный фольклор, особенно
наркоманский

4. Эндпоинт сохранения профиля: много блоков try-except, хотя каждый потенциально проблемный участок обернут в свой try-except,
что упрощает диагностику и логирование ошибок. Но это выглядит не читаемо! Ключевые этапы обработки (например, проверка файлов, публикация в Redis)
имеют свои try-except,  что защищает остальные части функции от падения (наверное).
Появится время - я займусь этим блоком и приведу его в человеческий вид!

5. Бардак в коде, после одобрения Евгением, надо перенести подписчик в отдельную директорию и файлы(модули) необходимые ему для работы.
   Не надо в контейнер пихать лишнее. Основное приложение надо тоже поместить в отдельный пакет
   (сделаю на этапе интеграции с бэком, который уже написан для нашего сайта)

6. Криво очень написаны докерфайлы (Отработать с Евгением, отрефакторить и впитать знания на будущие проекты)

7. Все ключи необходимо спрятать перед продакшеном, когда уже на нагрузочное тестирование пойдем и будем точно знать все сервисы,
    которые будем использовать (особенно касается ямл файла). Это уязвимое место в безопасности (в голове держу и исправлю)

8. При обновлении профиля надо удалять все старые записи(видео) из хранилища, заранее не продумал. В процессе реализации

9. Отсутствует кнопка и соответственно функционал удаления пользователя. Согласовать с командой и реализовать







ПУТИ К ФАЙЛАМ ДЛЯ ТЕСТА И ПЕРЕДАЧИ В СВАГГЕРЕ (ЭТО МАКСУ ДЛЯ РАБОТЫ ЧТО НА ЕНДПОИНТ ПРИЛЕТЕТЬ ДОЛЖНО!)

{
  "profile_data": {
    "activity_hobbies": "Долбиться в свое очко!",
    "adress": [
      "123 Example Street, Example City",
      "456 Another Street, Another City"
    ],
    "city": "Example City",
    "coordinates": [
      [
        37.7749,
        -122.4194
      ],
      [
        48.8566,
        2.3522
      ]
    ],
    "hashtags": [
      "#gaming",
      "#Diving",
      "#travel",
      "#photography"
    ],
    "is_in_mlm": 1,
    "is_incognito": false,
    "name": "Кусок ссанины",
    "wallet_number": "0x39b0B8cfa77fA65f36Ad186F649D36EBC7d4545",
    "website_or_social": "https://twitter.com/johndoe"
  },
  "image_data": {
    "image_path": "/user_logo/81a5be00-00f3-4811-9825-522ff0638343_4bad43da-ee9e-4a6d-a703-5f6683806bc8_c66f50f4ecb6aaf160ae3bd590effe68.jpg"
  },
  "video_data": {
    "video_path": "./video_temp/341bfb16-81ff-4802-b5a3-e10fe0370f3c_cat_cat.mp4"
  }
}



кошелек для тестов: 0x27b0B8cfa07fA60f36Ad953F679D36EBC7d4355



ДЛЯ ЭНДПОИНТА БЕЗ ВИДЕО

{
  "form_data": {
    "activity_hobbies": "Gaming, Traveling",
    "adress": [
      "123 Example Street, Example City",
      "456 Another Street, Another City"
    ],
    "city": "нахуй все",
    "coordinates": [
      [
        59.7700,
        37.6800
      ]
    ],
    "hashtags": [
      "#gaming",
      "#travel",
      "#photography"
    ],
    "is_in_mlm": 1,
    "is_incognito": false,
    "name": "Ебись все в рот!!!",
    "wallet_number": "0x39b0B8cfa77fA65f36Ad186F649D36EBC7d4545",
    "website_or_social": "https://twitter.com/johndoe"
  },
  "image_data": {
    "image_path": "/user_logo/81a5be00-00f3-4811-9825-522ff0638343_4bad43da-ee9e-4a6d-a703-5f6683806bc8_c66f50f4ecb6aaf160ae3bd590effe68.jpg"
  }
}





сколько строк кода?)

find . -type f -name "*.py" -not -path "./venv/*" -not -path "./.venv/*" -not -path "./env/*" -not -path "./.env/*" | xargs wc -l


босс валет 0x789132f1324d186619bD4F2E57D424f776ec3cdB













ВОРКЕР ЕСЛИ МОКИ НАДО БУДЕТ


""" Модуль реализации асинхронных функций для обработки видео и сохранения профиля в БД """

import time
import ffmpeg
from pathlib import Path
import aiofiles
import io
import urllib.parse
from uuid import uuid4
from prettyconf import config
import os
from dotenv import load_dotenv

from fastapi import HTTPException
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.future import select
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import HTTPException
from aiobotocore.session import get_session
from geoalchemy2 import Geometry
from geoalchemy2.shape import to_shape
from shapely.geometry import Point, MultiPoint
from typing import Optional

from models import UserProfiles, Hashtag, ProfileHashtag, User
from schemas import FormData
from utils import get_file_size, generate_unique_link



from logging_config import get_logger

logger = get_logger()

# Конфиги для канала редис
CHANNEL = config("CHANNEL", default="video_tasks")
REDIS_HOST = "redis"

PREVIEW_DURATION = 5  # Длительность превью


load_dotenv()

# Конфиги для облака
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
AWS_REGION = os.getenv("AWS_REGION")
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")


async def convert_to_h264(input_path, output_path, logger, mock_id=1):
    """Конвертация в H.264 с фиксированным именем mock_video_{id}"""
    start_time = time.time()

    # Фиксированное имя для мока
    mock_name = f"mock_video_{mock_id}"
    video_folder = os.path.join(output_path, mock_name)
    os.makedirs(video_folder, exist_ok=True)
    output_file = os.path.join(video_folder, f"{mock_name}.mp4")

    try:
        # Проверка исходного файла
        input_size = os.path.getsize(input_path) / (1024 * 1024)  # в MB
        logger.info(f"Начало конвертации: {input_path} -> {output_file} (размер: {input_size:.2f} MB)")

        # Получаем метаданные для адаптивного сжатия
        probe = ffmpeg.probe(input_path)
        video_stream = next((s for s in probe['streams'] if s['codec_type'] == 'video'), None)
        width = int(video_stream['width']) if video_stream else 1280

        # Параметры сжатия (остаются без изменений)
        args = {
            'vcodec': 'libx264',
            'preset': 'medium',
            'crf': 22 if width >= 1280 else 24,
            'pix_fmt': 'yuv420p',
            'movflags': '+faststart',
            'acodec': 'aac',
            'b:a': '128k' if width >= 1280 else '96k',
            'x264-params': 'ref=5:deblock=-1,-1:me=hex:subme=7:merange=16',
            'threads': '0',
            'loglevel': 'error'
        }

        # Запуск конвертации
        (
            ffmpeg
            .input(input_path)
            .output(output_file, **args)
            .overwrite_output()
            .run()
        )

        # Проверка результата
        output_size = os.path.getsize(output_file) / (1024 * 1024)
        duration = time.time() - start_time

        logger.info(
            f"Конвертация завершена за {duration:.2f} сек | "
            f"Размер: {output_size:.2f} MB | "
            f"CRF: {args['crf']}"
        )

        return {
            "video_path": output_file,
            "folder_path": video_folder,
            "original_size": input_size,
            "converted_size": output_size
        }

    except ffmpeg.Error as e:
        error_msg = e.stderr.decode('utf-8', errors='replace') if e.stderr else str(e)
        logger.error(f"Ошибка конвертации: {error_msg}")
        raise RuntimeError(f"Ошибка конвертации: {error_msg}")
    except Exception as e:
        logger.error(f"Неожиданная ошибка: {str(e)}")
        raise


async def create_hls_playlist(conversion_result: dict, logger, mock_id=1):
    """Генерация HLS с фиксированными именами mock_video_{id}"""
    input_video_path = conversion_result["converted_path"]
    video_folder = conversion_result["video_folder"]
    hls_dir = os.path.join(video_folder, "hls")
    os.makedirs(hls_dir, exist_ok=True)

    try:
        # Фиксированные имена для мока
        mock_name = f"mock_video_{mock_id}"
        master_playlist = f"{mock_name}.m3u8"
        segment_pattern = f"{mock_name}_%03d.ts"
        playlist_path = os.path.join(hls_dir, master_playlist)

        # Генерация HLS
        (
            ffmpeg
            .input(input_video_path)
            .output(
                playlist_path,
                format='hls',
                hls_time=5,
                hls_list_size=0,
                hls_segment_filename=os.path.join(hls_dir, segment_pattern),
                vcodec='copy',
                acodec='copy',
                start_number=0,
                hls_flags='independent_segments',
                loglevel='warning'
            )
            .overwrite_output()
            .run()
        )

        # Валидация
        first_segment = os.path.join(hls_dir, f"{mock_name}_000.ts")
        if not all([
            os.path.exists(playlist_path),
            os.path.exists(first_segment)
        ]):
            raise RuntimeError("Не все HLS файлы созданы")

        logger.info(f"HLS сгенерирован: {playlist_path}")
        return {
            "hls_dir": hls_dir,
            "master_playlist": playlist_path,
            "segment_pattern": f"{mock_name}_*.ts"
        }

    except ffmpeg.Error as e:
        error_msg = e.stderr.decode('utf-8', errors='replace') if e.stderr else str(e)
        logger.error(f"Ошибка генерации HLS: {error_msg}")
        raise HTTPException(status_code=500, detail=f"Ошибка генерации HLS: {error_msg}")
    except Exception as e:
        logger.error(f"Ошибка обработки HLS: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Ошибка обработки HLS: {str(e)}")


# Извлечение картинки из видео (для отображения постера на фронте)
async def extract_frame(video_path, posters_folder="user_video_posters", frame_time=2, logger=None):
    """
    Извлекает кадр из видео на указанной секунде, сохраняет его как изображение
    в папку `posters_folder` и возвращает путь к изображению.

    :param video_path: Путь к исходному видео.
    :param posters_folder: Папка для сохранения изображения (по умолчанию "user_video_posters").
    :param frame_time: Время в секундах, на котором нужно извлечь кадр (по умолчанию 2 секунды).
    :param logger: Логгер для записи сообщений.
    :return: Путь к сохранённому изображению в папке `posters_folder`.
    """
    start_time = time.time()

    # Создаем папку для постеров, если она не существует
    os.makedirs(posters_folder, exist_ok=True)

    # Генерируем уникальное имя файла с помощью uuid4
    unique_filename = f"{uuid4().hex}.jpg"  # Используем hex, чтобы убрать дефисы
    poster_path = os.path.join(posters_folder, unique_filename)  # Полный путь для сохранения

    try:
        if logger:
            logger.info(f"Извлечение кадра из видео: {video_path} -> {poster_path} (Время: {frame_time} сек.)")
        (
            ffmpeg
            .input(video_path, ss=frame_time)  # Указываем время, на котором нужно извлечь кадр
            .output(poster_path, vframes=1)  # Сохраняем только один кадр
            .overwrite_output()
            .run(capture_stdout=True, capture_stderr=True)
        )
        elapsed_time = time.time() - start_time
        if logger:
            logger.info(f"Извлечение кадра завершено: {poster_path} (Время: {elapsed_time:.2f} сек.)")
    except ffmpeg.Error as e:
        if logger:
            logger.error(f"Ошибка FFmpeg при извлечении кадра: {e.stderr.decode()}")
        raise RuntimeError("Не удалось извлечь кадр из видео")

    if logger:
        logger.info(f"Кадр успешно извлечён и сохранён: {poster_path}")

    # Возврат пути к изображению в папке `posters_folder`
    return poster_path


# Проверка соединения с AWS S3 перед загрузкой
async def check_s3_connection(logger):
    """ Проверка соединения с AWS S3 перед загрузкой. """
    try:
        async with get_session().create_client(
                "s3",
                region_name=AWS_REGION,
                aws_access_key_id=AWS_ACCESS_KEY_ID,
                aws_secret_access_key=AWS_SECRET_ACCESS_KEY
        ) as s3_client:
            # Проверка подключения, попытка получить список объектов из бакета
            await s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME)
            logger.info("Соединение с AWS S3 установлено успешно.")  # Лог об успешном соединении
            return True  # Возвращаем True, если соединение успешно
    except Exception as e:
        logger.error(f"Не удалось установить соединение с AWS S3: {e}")
        raise RuntimeError(f"Не удалось подключиться к AWS S3: {e}")


async def upload_to_s3(processing_data: dict, logger, mock_id=1) -> dict:
    """Рекурсивная загрузка папки в S3 с неймингом mock_video_{id}"""
    if processing_data.get("status") != "success":
        raise ValueError("Нет данных для загрузки")

    video_folder = processing_data["video_folder"]
    mock_name = f"mock_video_{mock_id}"  # Новый нейминг

    try:
        await check_s3_connection(logger)
        base_s3_path = f"videos/{mock_name}"  # Используем mock_name вместо folder_name

        async with get_session().create_client(
                "s3",
                region_name=AWS_REGION,
                aws_access_key_id=AWS_ACCESS_KEY_ID,
                aws_secret_access_key=AWS_SECRET_ACCESS_KEY
        ) as s3_client:
            # 1. Загружаем основное видео (не из папки hls)
            video_files = [f for f in os.listdir(video_folder)
                           if not f.startswith('.') and f != 'hls']

            if not video_files:
                raise FileNotFoundError("Основной видеофайл не найден")

            video_file = video_files[0]
            video_path = os.path.join(video_folder, video_file)

            # Переименовываем файл при загрузке
            await s3_client.put_object(
                Bucket=S3_BUCKET_NAME,
                Key=f"{base_s3_path}/{mock_name}.mp4",  # Новое имя файла
                Body=open(video_path, 'rb')
            )

            # 2. Рекурсивная загрузка папки hls с переименованием
            hls_dir = os.path.join(video_folder, "hls")
            if os.path.exists(hls_dir):
                for root, _, files in os.walk(hls_dir):
                    for file in files:
                        local_path = os.path.join(root, file)

                        # Генерируем новое имя файла
                        if file.endswith('.m3u8'):
                            new_name = f"{mock_name}.m3u8"
                        elif file.endswith('.ts'):
                            segment_num = file.split('_')[-1].split('.')[0]
                            new_name = f"{mock_name}_{segment_num}.ts"
                        else:
                            new_name = file

                        s3_key = f"{base_s3_path}/hls/{new_name}"

                        await s3_client.put_object(
                            Bucket=S3_BUCKET_NAME,
                            Key=s3_key,
                            Body=open(local_path, 'rb'),
                            ContentType="application/vnd.apple.mpegurl" if file.endswith('.m3u8') else "video/MP2T"
                        )

            # 3. Формируем URL с новыми именами
            return {
                "video_url": f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{base_s3_path}/{mock_name}.mp4",
                "preview_url": f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{base_s3_path}/hls/{mock_name}.m3u8"
            }

    except Exception as e:
        logger.error(f"Ошибка загрузки: {str(e)}", exc_info=True)
        raise RuntimeError(f"Ошибка загрузки в S3: {str(e)}")


# Логика удаления старых файлов с облака
async def delete_video_folder(video_url: str, logger) -> bool:
    """Удаляет все файлы по префиксу, кроме папок с 'mock' в названии"""
    try:
        parsed = urllib.parse.urlparse(video_url)
        path_parts = parsed.path.lstrip('/').split('/')

        # Проверяем, содержит ли путь слово 'mock'
        if any('mock' in part.lower() for part in path_parts):
            logger.info(f"Обнаружена папка 'mock' - удаление пропущено: {video_url}")
            return False

        prefix = '/'.join(path_parts[:-1]) + '/'

        logger.info(f"Начинаем удаление по префиксу: {prefix}")

        async with get_session().create_client(
                "s3",
                region_name=AWS_REGION,
                aws_access_key_id=AWS_ACCESS_KEY_ID,
                aws_secret_access_key=AWS_SECRET_ACCESS_KEY
        ) as s3:
            # Логируем запрос
            logger.info(f"Запрашиваем объекты для префикса: {prefix}")

            objects = await s3.list_objects_v2(
                Bucket=S3_BUCKET_NAME,
                Prefix=prefix
            )

            if not objects.get('Contents'):
                logger.warning(f"Не найдено объектов для удаления по префиксу: {prefix}")
                return False

            # Детальный лог объектов
            file_list = "\n".join([f" - {obj['Key']} ({obj['Size']} bytes)"
                                   for obj in objects['Contents']])
            logger.info(f"Найдены объекты для удаления:\n{file_list}")

            # Удаление с подтверждением
            response = await s3.delete_objects(
                Bucket=S3_BUCKET_NAME,
                Delete={
                    'Objects': [{'Key': obj['Key']} for obj in objects['Contents']],
                    'Quiet': False  # Получаем подробный ответ
                }
            )

            # Логируем результат
            if 'Deleted' in response:
                deleted_files = "\n".join([f" - {item['Key']}" for item in response['Deleted']])
                logger.info(f"Успешно удалены:\n{deleted_files}")

            if 'Errors' in response:
                errors = "\n".join([f" - {item['Key']}: {item['Message']}"
                                    for item in response['Errors']])
                logger.error(f"Ошибки при удалении:\n{errors}")
                return False

            return True

    except Exception as e:
        logger.error(f"КРИТИЧЕСКАЯ ОШИБКА: {str(e)}", exc_info=True)
        return False


# Логика удаления старой аватарки юзера и постера к видео
async def delete_old_media_files(
        old_logo_url: Optional[str],
        old_poster_url: Optional[str],
        logger
):
    """
    Удаление старых медиафайлов, кроме файлов с 'mock' в названии

    :param old_logo_url: Путь к старому логотипу
    :param old_poster_url: Путь к старому постеру
    :param logger: Логгер для записи событий
    """
    try:
        # Функция проверки на mock-файлы
        def is_mock_file(path: str) -> bool:
            return path and 'mock' in path.lower()

        # Обработка логотипа
        if old_logo_url and not is_mock_file(old_logo_url):
            logo_path = Path(old_logo_url)
            if logo_path.exists():
                os.unlink(logo_path)
                logger.info(f"Локальный файл логотипа удален: {logo_path}")
            else:
                logger.warning(f"Файл логотипа не найден: {logo_path}")
        elif old_logo_url:
            logger.info(f"Обнаружен mock-логотип, удаление пропущено: {old_logo_url}")

        # Обработка постера
        if old_poster_url and not is_mock_file(old_poster_url):
            poster_path = Path(old_poster_url)
            if poster_path.exists():
                os.unlink(poster_path)
                logger.info(f"Локальный файл постера удален: {poster_path}")
            else:
                logger.warning(f"Файл постера не найден: {poster_path}")
        elif old_poster_url:
            logger.info(f"Обнаружен mock-постер, удаление пропущено: {old_poster_url}")

    except Exception as e:
        logger.error(f"Ошибка при удалении локальных файлов: {e}", exc_info=True)
        # Не прерываем выполнение при ошибках


async def save_profile_to_db(session: AsyncSession, form_data: FormData, video_url: str, preview_url: str, poster_path: str, user_logo_url: str, wallet_number: str, logger):
    """
    Сохранение или обновление данных пользователя, логотипа и хэштегов в БД.
    """
    try:
        async with session.begin():
            # 1. Получаем пользователя по кошельку
            stmt = select(User).where(User.wallet_number == wallet_number)
            result = await session.execute(stmt)
            user = result.scalars().first()

            if not user:
                raise HTTPException(status_code=400, detail="Пользователь с данным кошельком не найден.")

            # 2. Удаление старых файлов из облака (если профиль уже существует)
            existing_profile_stmt = select(UserProfiles).where(UserProfiles.user_id == user.id)
            existing_profile_result = await session.execute(existing_profile_stmt)
            existing_profile = existing_profile_result.scalars().first()

            if existing_profile and existing_profile.video_url:
                try:
                    await delete_video_folder(existing_profile.video_url, logger)
                    logger.info(f"Старые файлы удалены из облака для {wallet_number}")
                except Exception as e:
                    logger.error(f"Ошибка удаления старых файлов: {e}")
                    # Не прерываем выполнение, если не удалось удалить файлы

            # 3. Получаем координаты из form_data
            coordinates = form_data.get("coordinates")

            # Преобразуем координаты в строку WKT, если они есть
            multi_point_wkt = None
            if coordinates:
                points = [Point(coord[0], coord[1]) for coord in coordinates]
                multi_point = MultiPoint(points)
                multi_point_wkt = str(multi_point)

            # 4. Проверка флага is_profile_created
            if not user.is_profile_created:
                # Генерируем уникальную ссылку только при создании нового профиля
                unique_link = await generate_unique_link()

                new_profile = UserProfiles(
                    name=form_data["name"],
                    website_or_social=form_data["website_or_social"],
                    activity_and_hobbies=form_data["activity_hobbies"],
                    video_url=video_url,
                    preview_url=preview_url,
                    user_logo_url=user_logo_url,
                    poster_url=poster_path,
                    adress=form_data["adress"],
                    city=form_data["city"],
                    coordinates=multi_point_wkt,
                    is_incognito=False,
                    is_moderated=False,
                    is_admin=False,
                    is_in_mlm=form_data["is_in_mlm"],
                    user_id=user.id,
                    language=form_data["language"],
                    user_link=unique_link  # Добавляем новую ссылку
                )

                user.is_profile_created = True
                session.add(new_profile)
                await session.flush()
                profile = new_profile

                logger.info(f"Создан новый профиль с уникальной ссылкой: {unique_link}")
            else:
                # Если профиль уже существует - получаем его текущие данные
                stmt = select(UserProfiles).where(UserProfiles.user_id == user.id)
                result = await session.execute(stmt)
                profile = result.scalars().first()

                # Проверяем, изменились ли медиафайлы
                old_logo_url = profile.user_logo_url
                old_poster_url = profile.poster_url

                if (old_logo_url and old_logo_url != user_logo_url) or \
                        (old_poster_url and old_poster_url != poster_path):
                    try:
                        await delete_old_media_files(
                            old_logo_url if old_logo_url != user_logo_url else None,
                            old_poster_url if old_poster_url != poster_path else None,
                            logger
                        )
                    except Exception as e:
                        logger.error(f"Ошибка при удалении старых медиафайлов: {e}")
                        # Продолжаем выполнение даже если не удалось удалить файлы

                # Сохраняем ВСЕ неизменяемые объекты при обновлении поля
                current_unique_link = profile.user_link
                current_is_admin = profile.is_admin
                current_is_moderated = profile.is_moderated

                # Обновляем только разрешенные для изменения поля
                profile.name = form_data["name"]
                profile.website_or_social = form_data["website_or_social"] if form_data["website_or_social"] is not None else None
                profile.activity_and_hobbies = form_data["activity_hobbies"] if form_data["activity_hobbies"] is not None else None
                profile.video_url = video_url
                profile.preview_url = preview_url
                profile.user_logo_url = user_logo_url
                profile.poster_url = poster_path
                profile.adress = form_data["adress"] if form_data["adress"] is not None else None
                profile.city = form_data["city"] if form_data["city"] is not None else None
                profile.coordinates = multi_point_wkt if coordinates is not None else None
                profile.is_incognito = False
                profile.is_in_mlm = form_data["is_in_mlm"] if form_data["is_in_mlm"] is not None else None
                profile.language = form_data["language"] if form_data["language"] is not None else None

                # Возвращаем неизменяемые поля
                profile.user_link = current_unique_link  # Сохраняем старую ссылку
                profile.is_admin = current_is_admin
                profile.is_moderated = current_is_moderated

                session.add(profile)
                logger.info(f"Профиль обновлен, уникальная ссылка сохранена: {current_unique_link}")

            # 5. Полная синхронизация хэштегов
            if form_data.get("hashtags"):
                # Получаем текущие хэштеги профиля
                current_hashtags_stmt = select(Hashtag).join(ProfileHashtag).where(
                    ProfileHashtag.profile_id == profile.id)
                current_hashtags_result = await session.execute(current_hashtags_stmt)
                current_hashtags = {tag.tag: tag for tag in current_hashtags_result.scalars().all()}

                # Нормализуем новые хэштеги
                new_tags = {tag.strip().lower().lstrip("#") for tag in form_data["hashtags"] if tag.strip()}

                # Удаляем отсутствующие хэштеги
                for tag_name, tag_obj in current_hashtags.items():
                    if tag_name not in new_tags:
                        delete_stmt = delete(ProfileHashtag).where(
                            ProfileHashtag.profile_id == profile.id,
                            ProfileHashtag.hashtag_id == tag_obj.id
                        )
                        await session.execute(delete_stmt)
                        logger.debug(f"Удалена связь с хэштегом: {tag_name}")

                # Добавляем новые хэштеги
                existing_tags_stmt = select(Hashtag).where(Hashtag.tag.in_(new_tags))
                existing_tags_result = await session.execute(existing_tags_stmt)
                existing_tags = {tag.tag: tag for tag in existing_tags_result.scalars().all()}

                for tag_name in new_tags:
                    if tag_name not in existing_tags:
                        new_hashtag = Hashtag(tag=tag_name)
                        session.add(new_hashtag)
                        await session.flush()
                        existing_tags[tag_name] = new_hashtag

                    # Проверяем и создаем связь при необходимости
                    link_stmt = select(ProfileHashtag).where(
                        ProfileHashtag.profile_id == profile.id,
                        ProfileHashtag.hashtag_id == existing_tags[tag_name].id
                    )
                    link_result = await session.execute(link_stmt)
                    if not link_result.scalars().first():
                        session.add(ProfileHashtag(
                            profile_id=profile.id,
                            hashtag_id=existing_tags[tag_name].id
                        ))

                logger.info(f"Обновлено хэштегов: {len(new_tags)}")

        await session.commit()
        logger.info(f"Данные успешно сохранены для кошелька {wallet_number}")

    except SQLAlchemyError as db_error:
        logger.error(f"Ошибка базы данных: {db_error}")
        await session.rollback()
        raise HTTPException(status_code=500, detail="Ошибка базы данных при сохранении видео")

    except Exception as e:
        logger.exception(f"Непредвиденная ошибка: {e}")
        await session.rollback()
        raise HTTPException(status_code=500, detail="Ошибка сохранения данных в базе")




